"""
Agent åŸºç±»å®šä¹‰
æ‰€æœ‰å…·ä½“ Agentï¼ˆQCã€Assemblyã€Annotation ç­‰ï¼‰çš„åŸºç¡€æ¥å£
"""
import abc
import uuid
import os
from pathlib import Path
from typing import Dict, Any, Optional, Callable, List

from .types import AgentStatus, StageResult, TaskSpec, AgentEvent, AgentCapability, AgentMetrics
from ...utils.logging import get_logger

# å»¶è¿Ÿå¯¼å…¥ LLM ç›¸å…³æ¨¡å—ï¼Œé¿å…å¯åŠ¨æ—¶ä¾èµ–æ£€æŸ¥
def _get_model_config_manager():
    """å»¶è¿Ÿå¯¼å…¥ ModelConfigManager"""
    try:
        from ..llm.config_manager import ModelConfigManager
        return ModelConfigManager
    except ImportError as e:
        logger.warning(f"LLM åŠŸèƒ½ä¸å¯ç”¨: {e}")
        return None

def _get_model_provider():
    """å»¶è¿Ÿå¯¼å…¥ ModelProvider"""
    try:
        from ..llm.provider import ModelProvider
        return ModelProvider
    except ImportError as e:
        logger.warning(f"LLM æä¾›è€…ä¸å¯ç”¨: {e}")
        return None

logger = get_logger(__name__)

# RAG å…±äº«å•ä¾‹ï¼ˆå»¶è¿Ÿåˆ›å»ºï¼‰
_SHARED_CHROMA = None

class HashEmbeddingFunction:
    """
    è½»é‡çº§æœ¬åœ°å“ˆå¸ŒåµŒå…¥å™¨ï¼ˆå®Œå…¨ç¦»çº¿ï¼‰ï¼š
    - å­—ç¬¦ n-gram (2..4)ï¼Œå›ºå®šç»´åº¦ 2048
    - é‡‡ç”¨ SHA1 å¯¹ n-gram æ˜ å°„åˆ°æ¡¶ï¼ŒTF è®¡æ•°ååš L2 å½’ä¸€åŒ–
    - å…¼å®¹ Chroma 1.1.xï¼šæä¾› __call__/embed_documents/embed_query/name/is_legacy
    """
    def __init__(self, n_features: int = 2048, ngram_min: int = 2, ngram_max: int = 4):
        self.n_features = int(n_features)
        self.ngram_min = int(ngram_min)
        self.ngram_max = int(ngram_max)

    def name(self):
        return "local-hash"

    def is_legacy(self):
        return True

    def _vectorize_one(self, text: str):
        import math, hashlib
        vec = [0.0] * self.n_features
        if not text:
            return vec
        t = text.replace("\n", " ").replace("\r", " ")
        n = len(t)
        for ngram_len in range(self.ngram_min, self.ngram_max + 1):
            if ngram_len <= 0 or ngram_len > n:
                continue
            for i in range(0, n - ngram_len + 1):
                g = t[i:i+ngram_len]
                h = hashlib.sha1(g.encode("utf-8")).digest()
                idx = int.from_bytes(h[:8], "big") % self.n_features
                vec[idx] += 1.0
        s = math.sqrt(sum(v*v for v in vec))
        if s > 0:
            vec = [v / s for v in vec]
        return vec

    def _vectorize(self, texts):
        if not texts:
            return []
        return [self._vectorize_one(x or "") for x in texts]

    def __call__(self, input):
        return self._vectorize(input)

    def embed_documents(self, input):
        return self._vectorize(input)

    def embed_query(self, input):
        if isinstance(input, str):
            return self._vectorize([input])
        return self._vectorize(input)

class BaseAgent(abc.ABC):
    """
    Agent åŸºç±» - å®šä¹‰ç»Ÿä¸€çš„ç”Ÿå‘½å‘¨æœŸå’Œæ¥å£
    
    æ‰€æœ‰ Agent å¿…é¡»å®ç°ï¼š
    1. prepare() - å‡†å¤‡é˜¶æ®µï¼ˆæ£€æŸ¥å·¥å…·ã€åˆ›å»ºç›®å½•ç­‰ï¼‰
    2. run() - æ ¸å¿ƒæ‰§è¡Œé€»è¾‘
    3. finalize() - æ¸…ç†å’Œåå¤„ç†
    4. get_capability() - è¿”å›èƒ½åŠ›æè¿°
    """
    
    def __init__(self, name: str, config: Optional[Dict[str, Any]] = None):
        self.name = name
        self.config = config or {}
        # RAG/Mem0 é»˜è®¤å¼€å¯ä¸é»˜è®¤å‚æ•°
        self.config.setdefault("enable_rag", True)
        self.config.setdefault("rag_top_k", 4)
        self.config.setdefault("enable_memory", True)
        # æ¯ä¸ª Agent ç‹¬ç«‹çš„ Mem0 å®¢æˆ·ç«¯ç¼“å­˜
        self._mem0 = None
        self.status = AgentStatus.IDLE
        self.current_task: Optional[TaskSpec] = None
        self.metrics = AgentMetrics()
        
        # äº‹ä»¶å›è°ƒ - ç”¨äºå‘ Supervisor æˆ– CLI æŠ¥å‘ŠçŠ¶æ€
        self.event_callback: Optional[Callable[[AgentEvent], None]] = None
        
        # å·¥ä½œç›®å½•å’Œæ—¥å¿—
        self.workdir: Optional[Path] = None
        self.logs_dir: Optional[Path] = None
        
        # LLM æä¾›è€… - å»¶è¿Ÿåˆå§‹åŒ–
        self._provider: Optional[ModelProvider] = None
        self._profile_name: Optional[str] = config.get("llm_profile") if config else None
    
    def set_event_callback(self, callback: Callable[[AgentEvent], None]):
        """è®¾ç½®äº‹ä»¶å›è°ƒå‡½æ•°"""
        self.event_callback = callback
    
    def emit_event(self, event_type: str, **payload):
        """å‘é€äº‹ä»¶åˆ°ä¸Šå±‚ï¼ˆSupervisor/CLIï¼‰"""
        if self.event_callback and self.current_task:
            event = AgentEvent(
                event_type=event_type,
                agent_name=self.name,
                task_id=self.current_task.task_id,
                payload=payload
            )
            self.event_callback(event)
            # Mem0 è®°å¿†é›†æˆï¼ˆå¯é€‰ï¼‰
            try:
                if self.config.get("enable_memory"):
                    self.memory_write({
                        "event_type": event_type,
                        "agent_name": self.name,
                        "task_id": self.current_task.task_id,
                        "tags": [self.name, event_type],
                        "payload": payload,
                    })
            except Exception:
                # è®°å¿†ä¸å¯ç”¨æ—¶é™é»˜è·³è¿‡
                pass
    
    def run_tool(self, exe: str, args, cwd: Path, env: Optional[dict] = None, timeout: Optional[int] = None) -> dict:
        """
        é€šç”¨å¤–éƒ¨å·¥å…·æ‰§è¡Œå™¨ï¼š
        - å…ˆç”¨ shutil.which æ£€æŸ¥å¯æ‰§è¡Œæ˜¯å¦å­˜åœ¨ï¼ˆå…è®¸ exe ä¸º 'spades.py'/'spades' ç­‰ï¼‰
        - ä½¿ç”¨ subprocess.run æ‰§è¡Œï¼ˆshell=Falseï¼‰ï¼Œå°† stdout/stderr å†™å…¥å·¥ä½œç›®å½•æ—¥å¿—æ–‡ä»¶
        - è¿”å›ä¸€ä¸ª dict: {exit_code, stdout_path, stderr_path, elapsed_sec}
        """
        import shutil, subprocess, time
        resolved = shutil.which(exe) or shutil.which(exe.split("/")[-1]) or shutil.which(exe.split("\\")[-1])
        if resolved is None:
            # Fallback: search in project's tools/bin via ToolsManager
            try:
                from ...utils.tools_manager import ToolsManager
                tm = ToolsManager(project_root=Path.cwd())
                tool_name = Path(exe).stem
                p = tm.where(tool_name)
                if p:
                    resolved = str(p)
            except Exception:
                resolved = None
        if resolved is None:
            return {"exit_code": 127, "stdout_path": "", "stderr_path": "", "elapsed_sec": 0.0}

        dry_run = bool(self.config.get("dry_run") or os.getenv("MITO_DRY_RUN"))
        stdout_path = Path(cwd) / f"{Path(exe).name}.stdout.log"
        stderr_path = Path(cwd) / f"{Path(exe).name}.stderr.log"
        if dry_run:
            # ä¸å®é™…æ‰§è¡Œï¼Œç›´æ¥è¿”å›æˆåŠŸ
            try:
                stdout_path.write_text("DRY RUN\\n")
                stderr_path.write_text("")
            except Exception:
                pass
            return {"exit_code": 0, "stdout_path": str(stdout_path), "stderr_path": str(stderr_path), "elapsed_sec": 0.0}

        cmd = [resolved] + list(args)
        env_all = os.environ.copy()
        
        # æ£€æŸ¥å·¥å…·æ˜¯å¦éœ€è¦condaç¯å¢ƒ
        tool_name = Path(exe).stem
        try:
            from ...utils.tool_env_manager import ToolEnvironmentManager
            env_mgr = ToolEnvironmentManager()
            
            # è·å–å·¥å…·éœ€è¦çš„ç¯å¢ƒåç§°
            required_env = env_mgr.get_tool_required_env(tool_name)
            
            if required_env:
                # æ£€æŸ¥ç¯å¢ƒæ˜¯å¦å­˜åœ¨
                if env_mgr.env_exists(required_env):
                    # æ³¨å…¥ç¯å¢ƒçš„binè·¯å¾„åˆ°PATH
                    env_bin_path = env_mgr.get_env_bin_path(required_env)
                    if env_bin_path:
                        env_all["PATH"] = f"{env_bin_path}:{env_all.get('PATH', '')}"
                        logger.info(f"Using conda environment: mito-forge-{required_env}")
                else:
                    logger.warning(f"Tool {tool_name} requires environment '{required_env}' but it's not installed")
                    logger.warning(f"Run: mito-forge doctor  # to setup environment")
        except Exception as e:
            logger.debug(f"Failed to setup tool environment: {e}")
        
        if env:
            env_all.update(env)
        start = time.time()
        with open(stdout_path, "w", encoding="utf-8") as out, open(stderr_path, "w", encoding="utf-8") as err:
            proc = subprocess.run(cmd, cwd=str(cwd), env=env_all, stdout=out, stderr=err, timeout=timeout or self.config.get("tool_timeout"))
        elapsed = time.time() - start
        return {"exit_code": proc.returncode, "stdout_path": str(stdout_path), "stderr_path": str(stderr_path), "elapsed_sec": elapsed}

    def execute_task(self, task: TaskSpec) -> StageResult:
        """
        æ‰§è¡Œå®Œæ•´ä»»åŠ¡æµç¨‹ - å¤–éƒ¨è°ƒç”¨çš„ä¸»å…¥å£
        åŒ…å«å®Œæ•´çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†å’Œå¼‚å¸¸å¤„ç†
        """
        self.current_task = task
        self.status = AgentStatus.PREPARING
        self.metrics = AgentMetrics()
        
        try:
            # å‘é€å¼€å§‹äº‹ä»¶
            self.emit_event("started", task_spec=task)
            
            # å‡†å¤‡é˜¶æ®µ
            self.prepare(task.workdir or Path("work") / task.task_id, **task.inputs)
            
            # æ‰§è¡Œé˜¶æ®µ
            self.status = AgentStatus.RUNNING
            result = self.run(task.inputs, **task.config)
            
            # å®Œæˆé˜¶æ®µ
            self.finalize()
            self.status = AgentStatus.FINISHED
            self.metrics.finish()
            
            # å¡«å……ç»“æœå…ƒæ•°æ®
            result.agent_name = self.name
            result.stage_name = task.agent_type
            result.agent_metrics = self.metrics
            
            # å‘é€å®Œæˆäº‹ä»¶
            self.emit_event("finished", result=result)
            
            return result
            
        except Exception as e:
            self.status = AgentStatus.FAILED
            self.metrics.finish()
            
            # åˆ›å»ºå¤±è´¥ç»“æœ
            error_result = StageResult(
                status=AgentStatus.FAILED,
                errors=[str(e)],
                agent_name=self.name,
                stage_name=task.agent_type if task else "unknown",
                agent_metrics=self.metrics
            )
            
            # å‘é€é”™è¯¯äº‹ä»¶
            self.emit_event("error", error=str(e), result=error_result)
            
            return error_result
        
        finally:
            self.current_task = None
    
    @abc.abstractmethod
    def prepare(self, workdir: Path, **kwargs) -> None:
        """
        å‡†å¤‡é˜¶æ®µ - åœ¨æ‰§è¡Œå‰çš„åˆå§‹åŒ–å·¥ä½œ
        
        Args:
            workdir: å·¥ä½œç›®å½•
            **kwargs: ä»»åŠ¡è¾“å…¥å‚æ•°
            
        åº”è¯¥åŒ…å«ï¼š
        - æ£€æŸ¥å¿…éœ€çš„å·¥å…·æ˜¯å¦å¯ç”¨
        - åˆ›å»ºå·¥ä½œç›®å½•ç»“æ„
        - éªŒè¯è¾“å…¥æ–‡ä»¶
        - è®¾ç½®æ—¥å¿—è·¯å¾„
        """
        pass
    
    @abc.abstractmethod
    def run(self, inputs: Dict[str, Any], **config) -> StageResult:
        """
        æ ¸å¿ƒæ‰§è¡Œé€»è¾‘
        
        Args:
            inputs: è¾“å…¥æ•°æ®å­—å…¸
            **config: é…ç½®å‚æ•°
            
        Returns:
            StageResult: æ ‡å‡†åŒ–æ‰§è¡Œç»“æœ
            
        åº”è¯¥åŒ…å«ï¼š
        - è°ƒç”¨å¤–éƒ¨å·¥å…·æˆ–æ‰§è¡Œç®—æ³•
        - å®æ—¶æŠ¥å‘Šè¿›åº¦ï¼ˆé€šè¿‡ emit_eventï¼‰
        - è§£æå·¥å…·è¾“å‡º
        - ç”Ÿæˆç»Ÿè®¡æŒ‡æ ‡
        """
        pass
    
    @abc.abstractmethod
    def finalize(self) -> None:
        """
        æ¸…ç†å’Œåå¤„ç†é˜¶æ®µ
        
        åº”è¯¥åŒ…å«ï¼š
        - æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        - ç§»åŠ¨ç»“æœæ–‡ä»¶åˆ°æœ€ç»ˆä½ç½®
        - ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
        - é‡Šæ”¾èµ„æº
        """
        pass
    
    @abc.abstractmethod
    def get_capability(self) -> AgentCapability:
        """
        è¿”å› Agent èƒ½åŠ›æè¿°
        ç”¨äº Supervisor è¿›è¡Œä»»åŠ¡åˆ†é…å†³ç­–
        """
        pass
    
    def get_status(self) -> AgentStatus:
        """è·å–å½“å‰çŠ¶æ€"""
        return self.status
    
    def cancel(self) -> bool:
        """
        å–æ¶ˆå½“å‰æ‰§è¡Œï¼ˆå¦‚æœæ”¯æŒï¼‰
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸå–æ¶ˆ
        """
        if self.status in (AgentStatus.RUNNING, AgentStatus.PREPARING):
            self.status = AgentStatus.CANCELLED
            self.emit_event("cancelled")
            return True
        return False
    
    def validate_inputs(self, inputs: Dict[str, Any]) -> List[str]:
        """
        éªŒè¯è¾“å…¥å‚æ•°
        
        Returns:
            List[str]: é”™è¯¯ä¿¡æ¯åˆ—è¡¨ï¼Œç©ºåˆ—è¡¨è¡¨ç¤ºéªŒè¯é€šè¿‡
        """
        errors = []
        capability = self.get_capability()
        
        # æ£€æŸ¥å¿…éœ€çš„è¾“å…¥ç±»å‹
        for input_type in capability.supported_inputs:
            if input_type not in inputs:
                errors.append(f"Missing required input: {input_type}")
        
        return errors
    
    def estimate_resources(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä¼°ç®—èµ„æºéœ€æ±‚
        
        Returns:
            Dict: åŒ…å« cpu_cores, memory_gb, disk_gb, estimated_time_sec ç­‰
        """
        capability = self.get_capability()
        return capability.resource_requirements.copy()
    
    # ========== LLM æä¾›è€…ç›¸å…³æ–¹æ³• ==========
    
    def get_llm_provider(self):
        """
        è·å– LLM æä¾›è€…å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
        
        Returns:
            ModelProvider: ç»Ÿä¸€çš„æ¨¡å‹æä¾›è€…ï¼Œå¦‚æœä¸å¯ç”¨åˆ™è¿”å› None
        """
        if self._provider is None:
            try:
                ModelConfigManager = _get_model_config_manager()
                if ModelConfigManager is None:
                    logger.warning(f"Agent {self.name}: LLM åŠŸèƒ½ä¸å¯ç”¨ï¼ŒModelConfigManager å¯¼å…¥å¤±è´¥")
                    return None
                
                config_manager = ModelConfigManager()
                if self._profile_name:
                    self._provider = config_manager.create_provider(self._profile_name)
                    logger.info(f"Agent {self.name} using LLM profile: {self._profile_name}")
                else:
                    self._provider = config_manager.create_provider_with_fallback()
                    logger.info(f"Agent {self.name} using default LLM provider with fallback")
            except Exception as e:
                logger.warning(f"Agent {self.name} LLM provider åˆå§‹åŒ–å¤±è´¥: {e}")
                logger.info(f"Agent {self.name} å°†åœ¨æ—  LLM æ¨¡å¼ä¸‹è¿è¡Œ")
                return None
        
        return self._provider
    
    def generate_llm_response(
        self, 
        prompt: str, 
        *, 
        system: Optional[str] = None,
        **kwargs
    ) -> str:
        """
        ç”Ÿæˆ LLM æ–‡æœ¬å“åº”çš„ä¾¿æ·æ–¹æ³•
        # RAG é›†æˆï¼ˆå¯é€‰ï¼‰
        try:
            if self.config.get("enable_rag"):
                prompt, _ = self.rag_augment(prompt, task=self.current_task, top_k=int(self.config.get("rag_top_k", 4)))
        except Exception:
            # RAG ä¸å¯ç”¨æ—¶é™é»˜è·³è¿‡
            pass
        
        Args:
            prompt: ç”¨æˆ·æç¤ºè¯
            system: ç³»ç»Ÿæç¤ºè¯
            **kwargs: å…¶ä»–å‚æ•°ï¼ˆtemperature, max_tokens ç­‰ï¼‰
            
        Returns:
            str: LLM ç”Ÿæˆçš„æ–‡æœ¬ï¼Œå¦‚æœ LLM ä¸å¯ç”¨åˆ™è¿”å›é»˜è®¤å“åº”
        """
        provider = self.get_llm_provider()
        
        if provider is None:
            # LLM ä¸å¯ç”¨æ—¶çš„é™çº§å¤„ç†
            logger.warning(f"Agent {self.name}: LLM ä¸å¯ç”¨ï¼Œè¿”å›é»˜è®¤å“åº”")
            return f"[LLMä¸å¯ç”¨] åŸºäºè§„åˆ™çš„åˆ†æç»“æœ - æç¤ºè¯: {prompt[:100]}..."
        
        # è®°å½• LLM è°ƒç”¨
        self.emit_event("llm_call", prompt_length=len(prompt), system_length=len(system or ""))
        
        try:
            response = provider.generate(prompt, system=system, **kwargs)
            logger.debug(f"Agent {self.name} LLM response length: {len(response)}")
            return response
        except Exception as e:
            logger.error(f"Agent {self.name} LLM generation failed: {e}")
            self.emit_event("llm_error", error=str(e))
            # é™çº§å¤„ç†è€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
            return f"[LLMé”™è¯¯] æ— æ³•ç”Ÿæˆå“åº”: {str(e)}"
    
    def generate_llm_json(
        self, 
        prompt: str, 
        *, 
        system: Optional[str] = None,
        schema: Optional[Dict[str, Any]] = None,
        max_retries: int = 3,
        **kwargs
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆç»“æ„åŒ– JSON å“åº”çš„ä¾¿æ·æ–¹æ³•
        # RAG é›†æˆï¼ˆå¯é€‰ï¼‰
        try:
            if self.config.get("enable_rag"):
                prompt, _ = self.rag_augment(prompt, task=self.current_task, top_k=int(self.config.get("rag_top_k", 4)))
        except Exception:
            pass
        
        Args:
            prompt: ç”¨æˆ·æç¤ºè¯
            system: ç³»ç»Ÿæç¤ºè¯
            schema: JSON Schema çº¦æŸ
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            Dict[str, Any]: è§£æåçš„ JSON å¯¹è±¡
        """
        provider = self.get_llm_provider()
        
        # è®°å½• LLM è°ƒç”¨
        self.emit_event("llm_json_call", 
                       prompt_length=len(prompt), 
                       system_length=len(system or ""),
                       has_schema=schema is not None)
        
        try:
            response = provider.generate_json(
                prompt, 
                system=system, 
                schema=schema, 
                max_retries=max_retries, 
                **kwargs
            )
            logger.debug(f"Agent {self.name} LLM JSON response keys: {list(response.keys())}")
            return response
        except Exception as e:
            logger.error(f"Agent {self.name} LLM JSON generation failed: {e}")
            self.emit_event("llm_json_error", error=str(e))
            raise
    
    def get_llm_info(self) -> Dict[str, Any]:
        """
        è·å–å½“å‰ LLM æä¾›è€…ä¿¡æ¯
        
        Returns:
            Dict: æä¾›è€…ä¿¡æ¯
        """
        try:
            provider = self.get_llm_provider()
            return provider.get_model_info()
        except Exception as e:
            return {"error": str(e), "available": False}
    
    # ========== RAG ä¸è®°å¿†é’©å­ï¼ˆé»˜è®¤è‡ªåŠ¨æ¢æµ‹ï¼Œå¯ç”¨å³å¯ç”¨ï¼‰ ==========
    def _get_shared_chroma(self):
        """
        è·å–å…±äº«çš„ Chroma å®¢æˆ·ç«¯ä¸é›†åˆã€‚åˆ›å»ºå¤±è´¥æ—¶è¿”å› Noneã€‚
        """
        global _SHARED_CHROMA
        if _SHARED_CHROMA is not None:
            return _SHARED_CHROMA
        try:
            from pathlib import Path as _P
            import chromadb
            base = _P("work") / "chroma"
            base.mkdir(parents=True, exist_ok=True)
            client = chromadb.PersistentClient(path=str(base))
            # ä»…ä½¿ç”¨æœ¬åœ° Hash åµŒå…¥ï¼ˆé»˜è®¤ç¦»çº¿ã€é›¶ä¾èµ–ï¼‰
            emb = HashEmbeddingFunction()

            collection = client.get_or_create_collection(
                name="knowledge",
                metadata={"hnsw:space": "cosine"},
                embedding_function=emb,
            )
            _SHARED_CHROMA = {"client": client, "collection": collection}
            return _SHARED_CHROMA
        except Exception:
            return None

    def _get_mem0(self):
        """
        è·å–ï¼ˆå¹¶ç¼“å­˜ï¼‰å½“å‰ Agent ç‹¬ç«‹çš„ Mem0 å®¢æˆ·ç«¯ã€‚å¤±è´¥æ—¶è¿”å› Noneã€‚
        """
        if getattr(self, "_mem0", None) is not None:
            return self._mem0
        try:
            from mem0 import Mem0
            self._mem0 = Mem0()
            return self._mem0
        except Exception:
            self._mem0 = None
            return None
    def rag_augment(self, prompt: str, task: Optional[TaskSpec] = None, top_k: int = 4) -> (str, List[Dict[str, Any]]):
        """
        ä½¿ç”¨ Chroma è¿›è¡Œæ£€ç´¢å¢å¼ºï¼Œè¿”å›å¢å¼ºåçš„æç¤ºä¸å¼•ç”¨æ¡ç›®ã€‚
        å¦‚ä¸å¯ç”¨åˆ™è¿”å›åŸå§‹æç¤ºä¸ç©ºåˆ—è¡¨ã€‚
        """
        # æ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡æ¨¡æ‹Ÿ RAG è¿”å›ï¼Œä¾¿äºæ— ä¾èµ–å¿«é€Ÿè”è°ƒ
        try:
            flag = (os.getenv("MITO_RAG_SIMULATE") or "").strip().lower()
            if flag in {"1", "true", "yes", "on"}:
                simulated_citations: List[Dict[str, Any]] = [
                    {"title": "æ¨¡æ‹ŸçŸ¥è¯†åº“æ¡ç›®ï¼šAssembly Best Practices", "source": "sim://kb/assembly_best_practices", "score": 0.99},
                    {"title": "æ¨¡æ‹ŸçŸ¥è¯†åº“æ¡ç›®ï¼šQC Parameters", "source": "sim://kb/qc_parameters", "score": 0.97},
                ]
                augmented = (
                    f"{prompt}"
                    + "\nå‚è€ƒèµ„æ–™ï¼ˆæ¨¡æ‹Ÿï¼‰ï¼š"
                    + "\n- " + simulated_citations[0]["title"]
                    + "\n- " + simulated_citations[1]["title"]
                )
                return augmented, simulated_citations
        except Exception:
            # è‹¥ç¯å¢ƒè¯»å–å¼‚å¸¸ï¼Œç»§ç»­æ­£å¸¸è·¯å¾„
            pass
        try:
            shared = self._get_shared_chroma()
            if not shared or "collection" not in shared or shared["collection"] is None:
                return prompt, []
            collection = shared["collection"]
            query_text = prompt
            res = collection.query(query_texts=[query_text], n_results=top_k)
            citations: List[Dict[str, Any]] = []
            docs = res.get("documents", [[]])[0]
            metas = res.get("metadatas", [[]])[0]
            for i, doc in enumerate(docs):
                meta = metas[i] if i < len(metas) else {}
                citations.append({
                    "title": meta.get("title") or meta.get("id") or f"doc_{i}",
                    "source": meta.get("source") or "",
                    "snippet": (doc or "")[:320],})
            if citations:
                lines = ["å‚è€ƒèµ„æ–™:"]
                lines += [f"- {c['title']}: {c['snippet']}" for c in citations]
                augmented = prompt + "\n" + "\n".join(lines)
                return augmented, citations
            return prompt, []
        except Exception:
            return prompt, []
    
    def memory_query(self, tags: List[str], top_k: int = 3) -> List[Dict[str, Any]]:
        """
        æŸ¥è¯¢ Mem0 è®°å¿†ï¼ˆçŸ­æœŸä¸Šä¸‹æ–‡ï¼‰ã€‚ä¸å¯ç”¨æ—¶è¿”å›ç©ºåˆ—è¡¨ã€‚
        æ¯ä¸ª Agent ä¿æŒç‹¬ç«‹çš„ Mem0 å®ä¾‹ã€‚
        """
        try:
            mem = self._get_mem0()
            if mem is None:
                return []
            items = mem.query({"tags": tags}, top_k=top_k)
            return items or []
        except Exception:
            return []
    
    def memory_write(self, event: Dict[str, Any]) -> None:
        """
        å†™å…¥ Mem0 è®°å¿†ï¼ˆé•¿æœŸå­˜å‚¨ï¼‰ã€‚ä¸å¯ç”¨æ—¶é™é»˜è·³è¿‡ã€‚
        æ¯ä¸ª Agent ä¿æŒç‹¬ç«‹çš„ Mem0 å®ä¾‹ã€‚
        """
        try:
            mem = self._get_mem0()
            if mem is None:
                return
            mem.write(event)
        except Exception:
            pass
    
    def auto_adjust_parameters(self, 
                              error_msg: str, 
                              current_params: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ ¹æ®é”™è¯¯ä¿¡æ¯è‡ªåŠ¨è°ƒæ•´å·¥å…·å‚æ•°
        
        è¿™æ˜¯ä¸€ä¸ªç®€å•çš„è§„åˆ™ç³»ç»Ÿï¼ŒåŸºäºå¸¸è§é”™è¯¯æ¨¡å¼è‡ªåŠ¨ä¿®å¤å‚æ•°ã€‚
        å¯ä»¥è¢«å­ç±»è¦†ç›–ä»¥å®ç°æ›´å¤æ‚çš„è°ƒæ•´é€»è¾‘ã€‚
        
        Args:
            error_msg: é”™è¯¯æ¶ˆæ¯
            current_params: å½“å‰å‚æ•°é…ç½®
        
        Returns:
            è°ƒæ•´åçš„å‚æ•°é…ç½®
        
        æ”¯æŒçš„é”™è¯¯ç±»å‹ï¼š
        - Out of Memory (OOM): å‡å°‘çº¿ç¨‹æ•°å’Œå†…å­˜ä½¿ç”¨
        - Timeout: å¢åŠ è¶…æ—¶æ—¶é—´
        - Input Format: å¯ç”¨ä¸¥æ ¼æ¨¡å¼
        - Disk Space: å¯ç”¨å‹ç¼©å’Œæ¸…ç†ä¸´æ—¶æ–‡ä»¶
        """
        adjusted = current_params.copy()
        error_lower = error_msg.lower()
        
        # å†…å­˜ä¸è¶³é”™è¯¯
        if any(keyword in error_lower for keyword in ["out of memory", "oom", "memory error", "cannot allocate"]):
            logger.info("ğŸ”§ Detected OOM error, adjusting memory-related parameters")
            
            # å‡å°‘çº¿ç¨‹æ•°
            if "threads" in adjusted:
                old_threads = adjusted["threads"]
                adjusted["threads"] = max(1, old_threads // 2)
                logger.info(f"   Reducing threads: {old_threads} â†’ {adjusted['threads']}")
            
            # å‡å°‘å†…å­˜å‚æ•°
            if "memory" in adjusted:
                old_mem = adjusted["memory"]
                adjusted["memory"] = max(1, int(old_mem * 0.6))
                logger.info(f"   Reducing memory: {old_mem}GB â†’ {adjusted['memory']}GB")
            
            # SPAdes ç‰¹å®šå‚æ•°
            if "careful" in adjusted:
                adjusted["careful"] = False
                logger.info("   Disabling careful mode to save memory")
        
        # è¶…æ—¶é”™è¯¯
        elif any(keyword in error_lower for keyword in ["timeout", "timed out", "time limit"]):
            logger.info("ğŸ”§ Detected timeout error, adjusting time-related parameters")
            
            if "timeout" in adjusted:
                old_timeout = adjusted["timeout"]
                adjusted["timeout"] = int(old_timeout * 1.5)
                logger.info(f"   Increasing timeout: {old_timeout}s â†’ {adjusted['timeout']}s")
            else:
                adjusted["timeout"] = 3600  # 1 hour default
                logger.info(f"   Setting timeout: {adjusted['timeout']}s")
        
        # è¾“å…¥æ ¼å¼é”™è¯¯
        elif any(keyword in error_lower for keyword in ["format", "invalid input", "parse error", "malformed"]):
            logger.info("ğŸ”§ Detected format error, enabling strict input handling")
            
            adjusted["careful_mode"] = True
            adjusted["ignore_errors"] = False
            logger.info("   Enabling careful mode and strict validation")
        
        # ç£ç›˜ç©ºé—´ä¸è¶³
        elif any(keyword in error_lower for keyword in ["disk", "no space", "storage", "write error"]):
            logger.info("ğŸ”§ Detected disk space error, enabling compression")
            
            adjusted["compress"] = True
            adjusted["keep_intermediate"] = False
            logger.info("   Enabling compression and removing intermediate files")
        
        # K-mer ç›¸å…³é”™è¯¯ï¼ˆç»„è£…å·¥å…·ç‰¹å®šï¼‰
        elif any(keyword in error_lower for keyword in ["kmer", "k-mer", "coverage too low"]):
            logger.info("ğŸ”§ Detected k-mer error, adjusting k-mer size")
            
            if "kmer" in adjusted or "k" in adjusted:
                key = "kmer" if "kmer" in adjusted else "k"
                old_k = adjusted[key]
                adjusted[key] = max(21, old_k - 10)  # å‡å° k-mer å¤§å°
                logger.info(f"   Reducing k-mer size: {old_k} â†’ {adjusted[key]}")
        
        # è¿”å›è°ƒæ•´åçš„å‚æ•°
        if adjusted != current_params:
            logger.info(f"âœ“ Parameters adjusted based on error pattern")
            return adjusted
        else:
            logger.debug("No parameter adjustments made")
            return current_params