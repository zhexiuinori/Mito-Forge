#!/usr/bin/env python3
"""
æµ‹è¯•ç»Ÿä¸€æ¨¡å‹æä¾›è€…çš„ç¤ºä¾‹è„šæœ¬
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ–°çš„æ¨¡å‹é…ç½®ç³»ç»Ÿ
"""

import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from mito_forge.core.llm.unified_provider import UnifiedProvider
from mito_forge.core.llm.config_manager import ModelConfigManager
from mito_forge.utils.logging import get_logger

logger = get_logger(__name__)

def test_unified_provider():
    """æµ‹è¯•ç»Ÿä¸€æä¾›è€…çš„åŸºæœ¬åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•ç»Ÿä¸€æ¨¡å‹æä¾›è€…")
    print("=" * 50)
    
    # 1. æ˜¾ç¤ºæ‰€æœ‰é¢„è®¾é…ç½®
    print("\nğŸ“‹ å¯ç”¨çš„é¢„è®¾é…ç½®:")
    presets = UnifiedProvider.get_preset_configs()
    for name, config in presets.items():
        print(f"  {name}: {config['default_model']} ({config['api_base']})")
    
    # 2. æµ‹è¯• Ollamaï¼ˆå¦‚æœå¯ç”¨ï¼‰
    print("\nğŸ¤– æµ‹è¯• Ollama æä¾›è€…:")
    try:
        ollama_provider = UnifiedProvider(
            provider_type="ollama",
            model="qwen2.5:7b"
        )
        
        if ollama_provider.is_available():
            print("  âœ… Ollama å¯ç”¨")
            try:
                response = ollama_provider.generate("ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹è‡ªå·±", max_tokens=100)
                print(f"  ğŸ“ æµ‹è¯•å“åº”: {response[:100]}...")
            except Exception as e:
                print(f"  âŒ ç”Ÿæˆå¤±è´¥: {e}")
        else:
            print("  âŒ Ollama ä¸å¯ç”¨ï¼ˆå¯èƒ½æœåŠ¡æœªå¯åŠ¨ï¼‰")
    except Exception as e:
        print(f"  âŒ Ollama æä¾›è€…åˆ›å»ºå¤±è´¥: {e}")
    
    # 3. æµ‹è¯• OpenAIï¼ˆå¦‚æœæœ‰ API å¯†é’¥ï¼‰
    print("\nğŸŒ æµ‹è¯• OpenAI æä¾›è€…:")
    openai_key = os.getenv("OPENAI_API_KEY")
    if openai_key:
        try:
            openai_provider = UnifiedProvider(
                provider_type="openai",
                model="gpt-4o-mini",
                api_key=openai_key
            )
            
            if openai_provider.is_available():
                print("  âœ… OpenAI å¯ç”¨")
                try:
                    response = openai_provider.generate("Hello, please introduce yourself briefly", max_tokens=50)
                    print(f"  ğŸ“ æµ‹è¯•å“åº”: {response[:100]}...")
                except Exception as e:
                    print(f"  âŒ ç”Ÿæˆå¤±è´¥: {e}")
            else:
                print("  âŒ OpenAI ä¸å¯ç”¨")
        except Exception as e:
            print(f"  âŒ OpenAI æä¾›è€…åˆ›å»ºå¤±è´¥: {e}")
    else:
        print("  âš ï¸  æœªè®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
    
    # 4. æµ‹è¯•è‡ªå®šä¹‰é…ç½®
    print("\nâš™ï¸  æµ‹è¯•è‡ªå®šä¹‰é…ç½®:")
    try:
        custom_config = {
            "provider_type": "openai_compatible",
            "model": "gpt-3.5-turbo",
            "api_base": "http://localhost:8000/v1",
            "api_key": "test-key"
        }
        
        custom_provider = UnifiedProvider.create_from_config(custom_config)
        print(f"  âœ… è‡ªå®šä¹‰æä¾›è€…åˆ›å»ºæˆåŠŸ: {custom_provider.get_model_info()}")
        
        # æ³¨æ„ï¼šè¿™ä¸ªæµ‹è¯•å¯èƒ½ä¼šå¤±è´¥ï¼Œå› ä¸ºæ²¡æœ‰å®é™…çš„æœåŠ¡å™¨
        if custom_provider.is_available():
            print("  âœ… è‡ªå®šä¹‰æœåŠ¡å¯ç”¨")
        else:
            print("  âŒ è‡ªå®šä¹‰æœåŠ¡ä¸å¯ç”¨ï¼ˆé¢„æœŸç»“æœï¼Œå› ä¸ºæ²¡æœ‰å®é™…æœåŠ¡å™¨ï¼‰")
            
    except Exception as e:
        print(f"  âŒ è‡ªå®šä¹‰æä¾›è€…åˆ›å»ºå¤±è´¥: {e}")

def test_config_manager():
    """æµ‹è¯•é…ç½®ç®¡ç†å™¨"""
    print("\nğŸ”§ æµ‹è¯•é…ç½®ç®¡ç†å™¨")
    print("=" * 50)
    
    try:
        config_manager = ModelConfigManager()
        
        # 1. æ˜¾ç¤ºé…ç½®æ–‡ä»¶ä½ç½®
        print(f"\nğŸ“ é…ç½®ç›®å½•: {config_manager.config_dir}")
        print(f"  ä¸»é…ç½®æ–‡ä»¶: {config_manager.config_file}")
        print(f"  é…ç½®æ–‡ä»¶: {config_manager.profiles_file}")
        
        # 2. åˆ—å‡ºæ‰€æœ‰é…ç½®æ–‡ä»¶
        print("\nğŸ“‹ å½“å‰é…ç½®æ–‡ä»¶:")
        profiles = config_manager.list_profiles()
        for profile in profiles:
            status = "âœ…" if profile["available"] else "âŒ"
            print(f"  {status} {profile['name']}: {profile['description']}")
        
        # 3. å°è¯•åˆ›å»ºæä¾›è€…
        print(f"\nğŸš€ å°è¯•åˆ›å»ºé»˜è®¤æä¾›è€…:")
        try:
            provider = config_manager.create_provider_with_fallback()
            info = provider.get_model_info()
            print(f"  âœ… æˆåŠŸåˆ›å»º: {info['provider_type']} - {info['model']}")
            
            # æµ‹è¯•ç”Ÿæˆ
            try:
                response = provider.generate("æµ‹è¯•", max_tokens=20)
                print(f"  ğŸ“ æµ‹è¯•ç”Ÿæˆ: {response[:50]}...")
            except Exception as e:
                print(f"  âŒ ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
                
        except Exception as e:
            print(f"  âŒ æ— æ³•åˆ›å»ºæä¾›è€…: {e}")
            print("  ğŸ’¡ æç¤º: è¯·è®¾ç½® API å¯†é’¥æˆ–å¯åŠ¨ Ollama æœåŠ¡")
        
    except Exception as e:
        print(f"âŒ é…ç½®ç®¡ç†å™¨æµ‹è¯•å¤±è´¥: {e}")

def test_json_generation():
    """æµ‹è¯• JSON ç”ŸæˆåŠŸèƒ½"""
    print("\nğŸ“„ æµ‹è¯• JSON ç”Ÿæˆ")
    print("=" * 50)
    
    try:
        config_manager = ModelConfigManager()
        provider = config_manager.create_provider_with_fallback()
        
        # æµ‹è¯• JSON ç”Ÿæˆ
        prompt = """
        è¯·ç”Ÿæˆä¸€ä¸ªåŒ…å«ä»¥ä¸‹ä¿¡æ¯çš„ JSON å¯¹è±¡ï¼š
        - name: ä¸€ä¸ªéšæœºçš„äººå
        - age: 20-60ä¹‹é—´çš„éšæœºå¹´é¾„
        - city: ä¸€ä¸ªåŸå¸‚å
        - hobbies: åŒ…å«2-3ä¸ªçˆ±å¥½çš„æ•°ç»„
        """
        
        print("ğŸ”„ ç”Ÿæˆ JSON å“åº”...")
        json_response = provider.generate_json(prompt, max_tokens=200)
        
        print("ğŸ“ ç”Ÿæˆçš„ JSON:")
        import json
        print(json.dumps(json_response, indent=2, ensure_ascii=False))
        
    except Exception as e:
        print(f"âŒ JSON ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§¬ Mito-Forge ç»Ÿä¸€æ¨¡å‹æä¾›è€…æµ‹è¯•")
    print("=" * 60)
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    os.environ.setdefault("MITO_FORGE_LOG_LEVEL", "INFO")
    
    try:
        # è¿è¡Œå„é¡¹æµ‹è¯•
        test_unified_provider()
        test_config_manager()
        test_json_generation()
        
        print("\n" + "=" * 60)
        print("âœ… æµ‹è¯•å®Œæˆï¼")
        print("\nğŸ’¡ ä½¿ç”¨æç¤º:")
        print("1. è¿è¡Œ 'python -m mito_forge.cli.main model list' æŸ¥çœ‹æ‰€æœ‰é…ç½®")
        print("2. è¿è¡Œ 'python -m mito_forge.cli.main model doctor' è¯Šæ–­é—®é¢˜")
        print("3. è¿è¡Œ 'python -m mito_forge.cli.main model presets' æŸ¥çœ‹é¢„è®¾é…ç½®")
        
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()